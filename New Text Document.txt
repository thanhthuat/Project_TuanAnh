import cv2
import numpy as np
from time import sleep
from datetime import datetime
import threading
import requests
import asyncio

import threading
import time
import requests
def loop1_10():
    for i in range(1, 11):
        time.sleep(1)
        print(i)

data = []
# def thingspeak_get(s):
#     get_data = requests.get("https://api.thingspeak.com/channels/1364808/fields/2.json?api_key=X8LAKDYR3DIXZN0M&results=2").json()
#     # response = TS.read()nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnthay the ten fields tai so 2
#     time.sleep(s)
#     print(get_data["channel"])
#     data = get_data["channel"]
#     return get_data["channel"]
#
# threading.Thread(target=thingspeak_get).start()

# Python 3.7+
# async def get_json(client, url):
#     async with client.get(url) as response:
#         assert response.status == 200
#         return await response.read()
# https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field1=1
def thingspeak_get(s):
    get_data = requests.get("https://api.thingspeak.com/channels/1364808/fields/3.json?api_key=X8LAKDYR3DIXZN0M&results=2").json()
    # response = TS.read()nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnthay the ten fields tai so 2
    print(get_data["feeds"])
    b = get_data['feeds']
    for i in b:
        data.append(i['field3'])
    print(data)
    time.sleep(1)
def thingspeak_post(s):
        if(s<21):
            get_data = requests.get("https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field3=0")
        elif (s>21 and s<26):
            get_data = requests.get("https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field3=10")
        print('post thinkspeak')
        time.sleep(s)

largura_min = 70
altura_min = 80
offset = 10
pos_linha = 550
delay = 60
detec = []
carros = 0
a = 0
start = time.time()
setup = 18
co=0
def pega_centro(x, y, w, h):
    x1 = int(w / 2)
    y1 = int(h / 2)
    cx = x + x1
    cy = y + y1
    return cx, cy
cap = cv2.VideoCapture('video.mp4')
prev_frame_time = 0
new_frame_time = 0
a = 0
subtracao = cv2.bgsegm.createBackgroundSubtractorMOG()

while True:
    ret, frame1 = cap.read()
    tempo = float(1 / delay)
    sleep(tempo)
    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(grey, (3, 3), 5)
    img_sub = subtracao.apply(blur)
    dilat = cv2.dilate(img_sub, np.ones((5, 5)))
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)
    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)
    contorno, h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cv2.line(frame1, (56, pos_linha), (1000, pos_linha), (255, 127, 0), 3)
    for (i, c) in enumerate(contorno):
        (x, y, w, h) = cv2.boundingRect(c)
        validar_contorno = (w >= largura_min) and (h >= altura_min)
        if not validar_contorno:
            continue
        cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(frame1, str(carros), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)
        centro = pega_centro(x, y, w, h)
        detec.append(centro)
        cv2.circle(frame1, centro, 4, (0, 0, 255), -1)
        for (x, y) in detec:
            if y < (pos_linha + offset) and y > (pos_linha - offset):
                carros += 1
                cv2.line(frame1, (50, pos_linha), (1200, pos_linha), (0, 127, 255), 3)
                cv2.rectangle(frame1, (x, y), (x + w, y + h), (255, 255, 0), 2)
                detec.remove((x, y))
                print("car is detected : " + str(carros))
    new_frame_time  = time.time()

    if setup > a - start > (setup - 0.2):
        start = time.time()
        co += 1
        if co % 2 == 0:
            if setup == 15:
                setup = 18
            elif setup == 20:
                setup = 18
            elif setup == 25:
                setup = 20
        else:
            if carros >=0 and carros<=15:
                print('dÃ¢ta__get=',data)


                if (data[1]== '10'):
                    setup = 25
                    print(setup)
                else:
                    setup = 20


            elif carros>15 and carros<50:
                setup = 25

        print("time : " + str(start))
    a = time.time()
    ret, frame = cap.read()
    fps = 1 / (new_frame_time - prev_frame_time)
    prev_frame_time = new_frame_time
    # converting the fps into integer
    fps = int(fps)
    # converting the fps to string so that we can display it on frame
    # by using putText function
    fps = str(fps)
    if co%2==0:
        cv2.putText(frame1, "VEHICLE COUNT : " + str(carros), (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)
        cv2.putText(frame1, "TIME RED + Yellow in lane: " + str(setup)+" S", (0, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    else:
        cv2.putText(frame1, "VEHICLE COUNT : " , (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        carros=0
        cv2.putText(frame1, "TIME BLUE in lane: " + str(setup)+" S", (0, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
    cv2.putText(frame1, "FPS: " + str(fps), (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    cv2.imshow("Video Original", frame1)
    cv2.imshow("Detectar", dilatada)
    if setup -2.8 > a - start > (setup - 2.85):
        data=[]
        threading.Thread(target=thingspeak_get,args=(setup,)).start()
            #threading.Thread(target=thingspeak_post, args=(setup,)).start()
    if cv2.waitKey(1) == 27:
        break
cv2.destroyAllWindows()
cap.release(200)

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
import cv2
import numpy as np
from time import sleep
from datetime import datetime
import threading
import requests
import asyncio

import threading
import time
import requests
def loop1_10():
    for i in range(1, 11):
        time.sleep(1)
        print(i)

data =[]
# def thingspeak_get(s):
#     get_data = requests.get("https://api.thingspeak.com/channels/1364808/fields/2.json?api_key=X8LAKDYR3DIXZN0M&results=2").json()
#     # response = TS.read()nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnthay the ten fields tai so 2
#     time.sleep(s)
#     print(get_data["channel"])
#     data = get_data["channel"]
#     return get_data["channel"]
#
# threading.Thread(target=thingspeak_get).start()

# Python 3.7+
# async def get_json(client, url):
#     async with client.get(url) as response:
#         assert response.status == 200
#         return await response.read()
# https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field1=1
def thingspeak_get(s):
    get_data = requests.get("https://api.thingspeak.com/channels/1364808/fields/1.json?api_key=X8LAKDYR3DIXZN0M&results=2").json()
    # response = TS.read()nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnthay the ten fields tai so 2
    print(get_data["feeds"])
    data=[]
    b = get_data['feeds']
    for i in b:
        data.append(i['field1'])
    print(data)
    time.sleep(s -3)
    return data

def thingspeak_post(s):
        if(s<21):
            get_data = requests.get("https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field3=0")
        elif (s>21 and s<26):
            get_data = requests.get("https://api.thingspeak.com/update?api_key=PQMQDCPX2DPAS41H&field3=10")
        print('post thinkspeak')
        time.sleep(s)

largura_min = 70
altura_min = 80
offset = 10
pos_linha = 550
delay = 60
detec = []
carros = 0
a = 0
start = time.time()
setup = 18
co=0
def pega_centro(x, y, w, h):
    x1 = int(w / 2)
    y1 = int(h / 2)
    cx = x + x1
    cy = y + y1
    return cx, cy
cap = cv2.VideoCapture('video.mp4')
prev_frame_time = 0
new_frame_time = 0
a = 0
subtracao = cv2.bgsegm.createBackgroundSubtractorMOG()

while True:
    ret, frame1 = cap.read()
    tempo = float(1 / delay)
    sleep(tempo)
    grey = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(grey, (3, 3), 5)
    img_sub = subtracao.apply(blur)
    dilat = cv2.dilate(img_sub, np.ones((5, 5)))
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)
    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)
    contorno, h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    cv2.line(frame1, (56, pos_linha), (1000, pos_linha), (255, 127, 0), 3)
    for (i, c) in enumerate(contorno):
        (x, y, w, h) = cv2.boundingRect(c)
        validar_contorno = (w >= largura_min) and (h >= altura_min)
        if not validar_contorno:
            continue
        cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(frame1, str(carros), (x, y - 15), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)
        centro = pega_centro(x, y, w, h)
        detec.append(centro)
        cv2.circle(frame1, centro, 4, (0, 0, 255), -1)
        for (x, y) in detec:
            if y < (pos_linha + offset) and y > (pos_linha - offset):
                carros += 1
                cv2.line(frame1, (50, pos_linha), (1200, pos_linha), (0, 127, 255), 3)
                cv2.rectangle(frame1, (x, y), (x + w, y + h), (255, 255, 0), 2)
                detec.remove((x, y))
                print("car is detected : " + str(carros))
    new_frame_time  = time.time()
    if setup > a - start > (setup - 0.2):
        start = time.time()
        co += 1
        if co % 2 == 0:
            if setup == 15:
                setup = 18
            elif setup == 20:
                setup = 18
            elif setup == 25:
                setup = 20
        else:
            if carros >=0 and carros<15:
                setup = 20
            elif carros>15 and carros<50:
                setup = 25

        print("time : " + str(start))
    a = time.time()
    ret, frame = cap.read()
    fps = 1 / (new_frame_time - prev_frame_time)
    prev_frame_time = new_frame_time
    # converting the fps into integer
    fps = int(fps)
    # converting the fps to string so that we can display it on frame
    # by using putText function
    fps = str(fps)
    if co%2==0:
        cv2.putText(frame1, "VEHICLE COUNT : " + str(carros), (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)
        cv2.putText(frame1, "TIME RED + Yellow in lane: " + str(setup)+" S", (0, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    else:
        cv2.putText(frame1, "VEHICLE COUNT : " , (450, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        carros=1
        cv2.putText(frame1, "TIME BLUE in lane: " + str(setup)+" S", (0, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
    cv2.putText(frame1, "FPS: " + str(fps), (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    cv2.imshow("Video Original", frame1)
    cv2.imshow("Detectar", dilatada)
    if setup -0.8 > a - start > (setup - 0.85):
             #threading.Thread(target=thingspeak_get,args=(setup,)).start()
            threading.Thread(target=thingspeak_post, args=(setup,)).start()
    if cv2.waitKey(1) == 27:
        break
cv2.destroyAllWindows()
cap.release(200)
